{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avito: O que é? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/arruda/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/arruda/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import scipy.stats as st\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from rake_nltk import Rake\n",
    "\n",
    "from helpers import save_model, load_model, limit_value\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_validate\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de auxilio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_uppercases_and_num_words(df, col_name):\n",
    "    uppercases = []\n",
    "    perc_uppercases = []\n",
    "    total_num_words = []\n",
    "    for text in df[col_name]:\n",
    "        text = str(text)\n",
    "        # remove numeros\n",
    "        text = re.sub('[0-9]+', '', text)\n",
    "        \n",
    "        total_uppers = sum(1 for c in text if c.isupper())\n",
    "        uppercases.append(total_uppers)\n",
    "        total = len(text)\n",
    "        if total == 0:\n",
    "            perc = 0.0\n",
    "        else:\n",
    "            perc = total_uppers/total\n",
    "        num_words = len(text.split(' '))\n",
    "        total_num_words.append(num_words)\n",
    "\n",
    "        perc_uppercases.append(perc)\n",
    "    \n",
    "    df[f'perc_uppercases_{col_name}'] = perc_uppercases\n",
    "    df[f'num_words_{col_name}'] = total_num_words\n",
    "    return df\n",
    "\n",
    "def return_text_cols_reduced(df):\n",
    "    \n",
    "    try:\n",
    "        description_reduced = load_from_disk('description_reduced.pkl')\n",
    "    except:\n",
    "        # Uses stopwords for russian from NLTK, and all puntuation characters.\n",
    "        r = Rake(language='russian')\n",
    "\n",
    "        total = df['description'].shape[0]\n",
    "\n",
    "        verbose_step_size = int(total/10)\n",
    "        description_reduced = []\n",
    "        for i, description in enumerate(df['description']):\n",
    "            r.extract_keywords_from_text(description)\n",
    "            phrases_and_scores = r.get_ranked_phrases_with_scores()  \n",
    "            if len(phrases_and_scores) <= 1:\n",
    "                description_reduced.append(description)\n",
    "                continue\n",
    "            mean_score = np.mean([x[0] for x in phrases_and_scores])\n",
    "\n",
    "            highest_phrases = [x[1] for x in phrases_and_scores if x[0] >= mean_score]\n",
    "            reduced_description = ' '.join(highest_phrases)\n",
    "            description_reduced.append(reduced_description)\n",
    "\n",
    "            if i % verbose_step_size == 0:\n",
    "                print(f'{int(i/total*100)}') \n",
    "        save_to_disk('description_reduced.pkl', description_reduced)\n",
    "                \n",
    "        \n",
    "    return description_reduced\n",
    "\n",
    "def transform_tfidf(col_vectorized):\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    tfidf_mat = tfidf_transformer.fit_transform(vectorized_col)\n",
    "    return tfidf_mat, tfidf_transformer\n",
    "\n",
    "def vectorized_texts_and_features(df):\n",
    "    stop_words = stopwords.words('russian')\n",
    "\n",
    "    tfidf_params = {\n",
    "        \"token_pattern\": r'\\w{1,}',\n",
    "        \"analyzer\": 'word',\n",
    "        \"sublinear_tf\": True,\n",
    "        \"dtype\": np.float32,\n",
    "        \"norm\": 'l2',\n",
    "        \"stop_words\": stop_words,\n",
    "        \"smooth_idf\":False\n",
    "    }\n",
    "\n",
    "    vectorizer = FeatureUnion([\n",
    "        ('description_reduced',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=16000,\n",
    "            **tfidf_params,\n",
    "            preprocessor=lambda x: x['description_reduced'])),\n",
    "        ('title',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            **tfidf_params,\n",
    "            #max_features=7000,\n",
    "            preprocessor=lambda x: x['title']))\n",
    "    ])\n",
    "\n",
    "\n",
    "    vectorizer.fit(df[['description_reduced', 'title']].to_dict('records'))\n",
    "    return vectorizer\n",
    "\n",
    "\n",
    "def save_to_disk(pkl_filename, data):\n",
    "    with open(pkl_filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "def load_from_disk(pkl_filename):\n",
    "    with open(pkl_filename, 'rb') as f:\n",
    "        pickle_data = pickle.load(f)\n",
    "        return pickle_data\n",
    "    \n",
    "def get_text_transformed_and_features_name(df):\n",
    "    try:\n",
    "        text_transformed = load_from_disk('text_transformed.pkl')\n",
    "        text_transformed = load_from_disk('tfidf_features_name.pkl')\n",
    "    except:\n",
    "        vectorizer = vectorized_texts_and_features(df)\n",
    "        text_transformed = vectorizer.transform(df.to_dict('records'))\n",
    "        tfidf_features_name = vectorizer.get_feature_names()\n",
    "        save_to_disk('text_transformed.pkl', text_transformed)\n",
    "        save_to_disk('tfidf_features_name.pkl', tfidf_features_name)\n",
    "    return text_transformed, tfidf_features_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções auxiliares pegas do notebook do victor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(klass, **params):\n",
    "    '''Inicializa o model, com os argumentos que são passados opcionalmente\n",
    "    \n",
    "    Entrada:\n",
    "        clf: Classe do modelo\n",
    "        **params: Parâmetros a serem passados para o modelo, no momento da inicialização\n",
    "        \n",
    "    Saída:\n",
    "        O modelo inicializado\n",
    "    '''\n",
    "    c = klass()\n",
    "    c.set_params(**params)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(klass, X_train, y_train, k=10, \n",
    "                  scoring=['neg_mean_squared_error'], rt_train=False):\n",
    "    '''Realiza o treinamento e a validação, utilizando o cross-validation, e calcula as métricas desejadas\n",
    "    \n",
    "    Entrada:\n",
    "        klass: modelo a ser treinado\n",
    "        X_train: Conjunto de dados de treinamento\n",
    "        y_train: resultados de cada exemplo do conjunto de dados\n",
    "        k: Quantidade de folds a serem usados na cross-validation; a cada iteração (k-1) folds \n",
    "            são usados para treino e o fold remanescente é utilizado para validação\n",
    "        scoring: Lista de métricas a serem calculadas para cada iteração da cross-validation\n",
    "        rt_train: Decide se as métricas calculadas para o conjunto de treinamento são retornadas ou não\n",
    "        \n",
    "    Saída:\n",
    "        scores: Dicionário contendo as métricas de cada iteração da cross-validation\n",
    "        \n",
    "    '''\n",
    "    scores = cross_validate(klass, X_train, y_train, cv=k, scoring=scoring, return_train_score=rt_train)        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(clf_scores, metrics):\n",
    "    '''Plota métricas específicas para os diversos modelos empregados.\n",
    "    \n",
    "    Entrada:\n",
    "        clf_scores: Dicionário com as métricas dos modelos\n",
    "        metrics: Métricas a serem plotadas\n",
    "        \n",
    "    Saída:\n",
    "        Gráfico com as métricas exibido na célula de saída\n",
    "    '''\n",
    "    \n",
    "    warnings.filterwarnings('ignore')\n",
    "    for i, metric in enumerate(metrics):\n",
    "#         plt.figure(figsize=(12,22))\n",
    "        plt.figure(figsize=(20,10))\n",
    "        for score in clf_scores:\n",
    "            x = range( len( clf_scores[score][metric]) )\n",
    "            y = clf_scores[score][metric]\n",
    "            plt.subplot(len(metrics),1,i+1)\n",
    "            plt.plot(x, y, alpha=0.3)\n",
    "            plt.scatter(x, y, label='{0}, média: {1}'.format(score, round(y.mean(),3)))\n",
    "            plt.xticks(x)\n",
    "            plt.xlabel('iteração', fontsize='large')\n",
    "            plt.title('{0} na validação'.format(metric.split('_')[1]),  fontsize='large')\n",
    "            plt.legend(loc='best', fontsize='large')\n",
    "            plt.grid('on')\n",
    "    plt.show()\n",
    "    warnings.filterwarnings('default')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode image_top_1\n",
      "encode city\n",
      "encode region\n",
      "encode parent_category_name\n",
      "encode category_name\n",
      "encode user_type\n",
      "encode param_1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "_train_complete_df = pd.read_csv('train.csv.zip', compression='zip', index_col = \"item_id\")\n",
    "train_complete_df = _train_complete_df.copy()\n",
    "\n",
    "_submission_df = pd.read_csv('test.csv.zip', compression='zip', index_col = \"item_id\")\n",
    "submission_df = _submission_df.copy()\n",
    "\n",
    "train_complete_index = train_complete_df.index\n",
    "submission_index = submission_df.index\n",
    "\n",
    "y = train_complete_df['deal_probability'].copy()\n",
    "train_complete_df.drop(\"deal_probability\",axis=1, inplace=True)\n",
    "\n",
    "full_df = pd.concat([train_complete_df,submission_df], axis=0)\n",
    "del train_complete_df, submission_df\n",
    "\n",
    "# transformando descrições nulas em str vazias\n",
    "full_df['description'] = full_df['description'].replace(np.nan, '', regex=True)\n",
    "\n",
    "full_df['price'] = np.log(full_df['price']+0.001)\n",
    "full_df['price'].fillna(-999,inplace=True)\n",
    "full_df['image_top_1'].fillna(-999,inplace=True)\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "cat_features = [\n",
    "    'image_top_1',\n",
    "    'city',\n",
    "    'region',\n",
    "    'parent_category_name',\n",
    "    'category_name',\n",
    "    'user_type',\n",
    "    'param_1'\n",
    "]\n",
    "for feature_name in cat_features:\n",
    "    print(f'encode {feature_name}')\n",
    "    full_df[feature_name] = label_encoder.fit_transform(full_df[feature_name].astype(str))\n",
    "\n",
    "full_df = apply_uppercases_and_num_words(full_df, 'description')\n",
    "full_df = apply_uppercases_and_num_words(full_df, 'title')\n",
    "\n",
    "full_df['description_reduced'] = return_text_cols_reduced(full_df)\n",
    "\n",
    "text_transformed, tfidf_features_name = get_text_transformed_and_features_name(full_df)\n",
    "    \n",
    "train_complete_df = full_df.loc[train_complete_index,:].copy()\n",
    "submission_df = full_df.loc[submission_index,:].copy()\n",
    "\n",
    "del full_df\n",
    "gc.collect()\n",
    "\n",
    "train_complete_df['deal_probability'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'price', \n",
    "    'item_seq_number', \n",
    "    'image_top_1', \n",
    "    'city',\n",
    "    'region',\n",
    "    'parent_category_name',\n",
    "    'category_name',\n",
    "    'user_type',\n",
    "    'param_1'\n",
    "]\n",
    "\n",
    "features.extend([\n",
    "    'perc_uppercases_description',\n",
    "    'perc_uppercases_title',\n",
    "    'num_words_description',\n",
    "    'num_words_title',\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junção das features do dataset com as features de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hstack([\n",
    "    csr_matrix(train_complete_df[features].values), \n",
    "    text_transformed[0:train_complete_index.shape[0]]\n",
    "])\n",
    "submission_X = hstack([csr_matrix(submission_df[features].values), text_transformed[train_complete_index.shape[0]:]])\n",
    "\n",
    "# final_features_list = features + tfidf_features_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação entre train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123654)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparativo entre modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_params = {'kernel':'rbf', 'cache_size': 4000}\n",
    "# svm = create_model(SVR, **svm_params)\n",
    "\n",
    "# svm_scores = compute_score(svm, X_train, y_train)\n",
    "# scores['svm'] = svm_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = create_model(LinearRegression, **{n_jobs=6})\n",
    "\n",
    "lr_scores = compute_score(lr, X_train, y_train)\n",
    "scores['lr'] = lr_scores\n",
    "\n",
    "save_to_disk('score3.pkl', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_params = {'hidden_layer_sizes': (100, 100, 100), 'activation': 'logistic', 'tol': 0.00001}\n",
    "nn = create_model(MLPRegressor, **nn_params)\n",
    "\n",
    "\n",
    "nn_scores = compute_score(nn, X_train, y_train)\n",
    "scores['nn'] = nn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_disk('score2.pkl', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=6, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=0, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f427951a978>, 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f422cacfb38>, 'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f42795099e8>, 'colsample_bytree...51a588>, 'min_child_weight': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f427951a588>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_left = st.beta(10, 1)  \n",
    "from_zero_positive = st.expon(0, 50)\n",
    "\n",
    "params = {  \n",
    "    \"n_estimators\": st.randint(3, 40),\n",
    "    \"max_depth\": st.randint(3, 40),\n",
    "    \"learning_rate\": st.uniform(0.05, 0.4),\n",
    "    \"colsample_bytree\": one_to_left,\n",
    "    \"subsample\": one_to_left,\n",
    "    \"gamma\": st.uniform(0, 10),\n",
    "    'reg_alpha': from_zero_positive,\n",
    "    \"min_child_weight\": from_zero_positive,\n",
    "}\n",
    "\n",
    "xgb_reg = create_model(XGBRegressor, **{'reg_lambda':0, 'n_jobs':6}) \n",
    "\n",
    "gs = RandomizedSearchCV(xgb_reg, params, n_jobs=1)  \n",
    "gs.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg_best = gs.best_estimator_\n",
    "xgb_scores = compute_score(xgb_reg_best, X_train, y_train)\n",
    "\n",
    "scores['xbg'] = xgb_scores\n",
    "save_to_disk('score.pkl', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(scores, ['test_neg_mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
